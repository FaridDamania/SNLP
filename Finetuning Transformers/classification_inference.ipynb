{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "IMDB = pd.read_csv(\"/Users/fariddamania/Downloads/SEM VII/SNLP/Dataset/IMDB Dataset.csv\")\n",
    "IMDB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_label = {0: \"negative\", 1: \"positive\"}\n",
    "label_to_id = {label: id_ for id_, label in id_to_label.items()}\n",
    "\n",
    "IMDB[\"label\"] = IMDB[\"sentiment\"].map(label_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  label\n",
       "0  One of the other reviewers has mentioned that ...  positive      1\n",
       "1  A wonderful little production. <br /><br />The...  positive      1\n",
       "2  I thought this was a wonderful way to spend ti...  positive      1\n",
       "3  Basically there's a family where a little boy ...  negative      0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(IMDB.shape)\n",
    "IMDB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"max_length\": 360,\n",
    "    \"model_path\": \"microsoft/xtremedistil-l6-h256-uncased\",\n",
    "    \"output_dir\": \"./my_model_output\",\n",
    "    \"train_batch_size\": 64,\n",
    "    \"valid_batch_size\": 64,\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"epochs\": 3,\n",
    "    \"debug\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "tokenizer_model = transformers.AutoTokenizer.from_pretrained(model_config[\"model_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "train_data, valid_data = model_selection.train_test_split(\n",
    "    IMDB,\n",
    "    test_size=0.2,\n",
    "    random_state=123,\n",
    "    shuffle=True,\n",
    "    stratify=IMDB[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SentimentDataset:\n",
    "    \n",
    "    def __init__(self, dataset, tokenizer, config):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = config[\"max_length\"]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataset.iloc[index]\n",
    "        \n",
    "        encoded = self.tokenizer(\n",
    "            row[\"review\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": encoded[\"input_ids\"].squeeze(0), \n",
    "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(row[\"label\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentimentDataset(train_data, tokenizer_model, model_config)\n",
    "valid_dataset = SentimentDataset(valid_data, tokenizer_model, model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1045,  2387,  1996,  3185,  2044,  9361,  2049,  5790,  2006,\n",
       "         10047, 18939,  1012,  2067,  2059,  1010,  2009,  2001,  2012,  1022,\n",
       "          1012,  1014,  1998,  1045,  2245,  1010,  1000, 10166,   999,  2008,\n",
       "          2442,  2022,  1037,  2204,  2028,  1000,  1012,  1045,  2245,  3308,\n",
       "          1012,  1996,  2927,  1997,  1996,  3185,  2941,  7906,  2054,  1996,\n",
       "          5436, 10659,  1010,  2021,  2059,  2009,  3632, 27258,  2135,  2091,\n",
       "          7650,  2049,  8102,  1012,  1045,  2228,  2302,  1996,  2839,  1997,\n",
       "         14411, 23330,  1010,  2009,  2453,  2031,  2042, 10303,  1011,  2348,\n",
       "          2002,  2003,  1996,  3114,  1996,  2466,  2240,  3138,  1996,  2607,\n",
       "          2009,  2515,  1012,  1996,  2839,  2003,  2074,  2205,  6034,  2005,\n",
       "          2026, 16663,  1010,  1998,  2524,  2000, 18094,  1012,  2036,  1010,\n",
       "          1996,  4990,  1996,  2364,  2839,  3138,  2013,  1996,  2927,  1997,\n",
       "          1996,  2466,  6229,  2049,  1000, 14463,  1000,  2012,  1996,  2203,\n",
       "          2003,  6576, 22537,  1998,  2071,  4089,  2031,  2042, 16647,  1011,\n",
       "          1996,  4522,  2003,  1010,  1045,  2074,  2106,  2025,  3305,  1996,\n",
       "          3185,  1012,  1026,  7987,  1013,  1028,  1026,  7987,  1013,  1028,\n",
       "          2348,  1045,  2442,  6449,  2008,  2009,  2003,  1000,  3733,  3666,\n",
       "          1000,  1010,  1998,  1045,  2018,  2053,  3471,  3564,  2083,  1996,\n",
       "          2878,  3185,  1010,  2043,  2009,  2018,  2736,  1045,  2001,  5399,\n",
       "          4895,  5714, 19811,  2011,  1996,  4566,  1012,  2035,  1999,  2035,\n",
       "          1010,  2738, 19960,  3695, 16748,  1012,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/xtremedistil-l6-h256-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "classification_model = transformers.AutoModelForSequenceClassification.from_pretrained(model_config['model_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate_metrics(eval_result):\n",
    "    logits, true_labels = eval_result\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    return {\n",
    "        \"f1\": metrics.f1_score(true_labels, predictions, average=\"weighted\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=model_config[\"output_dir\"],\n",
    "    per_device_train_batch_size=model_config[\"train_batch_size\"],\n",
    "    per_device_eval_batch_size=model_config[\"valid_batch_size\"],\n",
    "    learning_rate=model_config[\"learning_rate\"],\n",
    "    num_train_epochs=model_config[\"epochs\"],\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=classification_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer_model,\n",
    "    compute_metrics=evaluate_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92f47f146ec42618a523e6ae6e2df07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6809, 'grad_norm': 0.5785415172576904, 'learning_rate': 2.9840000000000002e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6302, 'grad_norm': 0.9751928448677063, 'learning_rate': 2.968e-05, 'epoch': 0.03}\n",
      "{'loss': 0.5626, 'grad_norm': 2.5507569313049316, 'learning_rate': 2.9520000000000002e-05, 'epoch': 0.05}\n",
      "{'loss': 0.5189, 'grad_norm': 3.1713480949401855, 'learning_rate': 2.936e-05, 'epoch': 0.06}\n",
      "{'loss': 0.4882, 'grad_norm': 2.110952138900757, 'learning_rate': 2.92e-05, 'epoch': 0.08}\n",
      "{'loss': 0.4429, 'grad_norm': 5.068164825439453, 'learning_rate': 2.904e-05, 'epoch': 0.1}\n",
      "{'loss': 0.4336, 'grad_norm': 2.3121767044067383, 'learning_rate': 2.888e-05, 'epoch': 0.11}\n",
      "{'loss': 0.4261, 'grad_norm': 2.1600167751312256, 'learning_rate': 2.8720000000000003e-05, 'epoch': 0.13}\n",
      "{'loss': 0.3866, 'grad_norm': 8.545737266540527, 'learning_rate': 2.856e-05, 'epoch': 0.14}\n",
      "{'loss': 0.4149, 'grad_norm': 5.2312164306640625, 'learning_rate': 2.84e-05, 'epoch': 0.16}\n",
      "{'loss': 0.4013, 'grad_norm': 4.442758560180664, 'learning_rate': 2.824e-05, 'epoch': 0.18}\n",
      "{'loss': 0.3969, 'grad_norm': 2.9399359226226807, 'learning_rate': 2.8080000000000002e-05, 'epoch': 0.19}\n",
      "{'loss': 0.4043, 'grad_norm': 2.9444613456726074, 'learning_rate': 2.792e-05, 'epoch': 0.21}\n",
      "{'loss': 0.3734, 'grad_norm': 6.557764053344727, 'learning_rate': 2.7760000000000002e-05, 'epoch': 0.22}\n",
      "{'loss': 0.3365, 'grad_norm': 4.5088653564453125, 'learning_rate': 2.7600000000000003e-05, 'epoch': 0.24}\n",
      "{'loss': 0.3375, 'grad_norm': 3.3068032264709473, 'learning_rate': 2.7439999999999998e-05, 'epoch': 0.26}\n",
      "{'loss': 0.3374, 'grad_norm': 2.2308738231658936, 'learning_rate': 2.728e-05, 'epoch': 0.27}\n",
      "{'loss': 0.3149, 'grad_norm': 3.1722707748413086, 'learning_rate': 2.712e-05, 'epoch': 0.29}\n",
      "{'loss': 0.3616, 'grad_norm': 3.3358285427093506, 'learning_rate': 2.696e-05, 'epoch': 0.3}\n",
      "{'loss': 0.3366, 'grad_norm': 3.2932090759277344, 'learning_rate': 2.68e-05, 'epoch': 0.32}\n",
      "{'loss': 0.3192, 'grad_norm': 3.3292243480682373, 'learning_rate': 2.6640000000000002e-05, 'epoch': 0.34}\n",
      "{'loss': 0.3158, 'grad_norm': 5.603553771972656, 'learning_rate': 2.648e-05, 'epoch': 0.35}\n",
      "{'loss': 0.3074, 'grad_norm': 1.9864611625671387, 'learning_rate': 2.632e-05, 'epoch': 0.37}\n",
      "{'loss': 0.3299, 'grad_norm': 4.009589672088623, 'learning_rate': 2.616e-05, 'epoch': 0.38}\n",
      "{'loss': 0.3176, 'grad_norm': 5.304008483886719, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.4}\n",
      "{'loss': 0.3091, 'grad_norm': 3.131197690963745, 'learning_rate': 2.584e-05, 'epoch': 0.42}\n",
      "{'loss': 0.3111, 'grad_norm': 1.7750592231750488, 'learning_rate': 2.568e-05, 'epoch': 0.43}\n",
      "{'loss': 0.3233, 'grad_norm': 2.713350296020508, 'learning_rate': 2.552e-05, 'epoch': 0.45}\n",
      "{'loss': 0.3087, 'grad_norm': 2.596372365951538, 'learning_rate': 2.536e-05, 'epoch': 0.46}\n",
      "{'loss': 0.2857, 'grad_norm': 4.176917552947998, 'learning_rate': 2.52e-05, 'epoch': 0.48}\n",
      "{'loss': 0.2772, 'grad_norm': 6.099401473999023, 'learning_rate': 2.504e-05, 'epoch': 0.5}\n",
      "{'loss': 0.2822, 'grad_norm': 4.1318793296813965, 'learning_rate': 2.4880000000000002e-05, 'epoch': 0.51}\n",
      "{'loss': 0.2619, 'grad_norm': 2.5188558101654053, 'learning_rate': 2.472e-05, 'epoch': 0.53}\n",
      "{'loss': 0.2729, 'grad_norm': 4.582728385925293, 'learning_rate': 2.456e-05, 'epoch': 0.54}\n",
      "{'loss': 0.2828, 'grad_norm': 6.67326545715332, 'learning_rate': 2.44e-05, 'epoch': 0.56}\n",
      "{'loss': 0.2671, 'grad_norm': 3.548370599746704, 'learning_rate': 2.4240000000000002e-05, 'epoch': 0.58}\n",
      "{'loss': 0.2951, 'grad_norm': 5.483756065368652, 'learning_rate': 2.408e-05, 'epoch': 0.59}\n",
      "{'loss': 0.2679, 'grad_norm': 5.719096660614014, 'learning_rate': 2.392e-05, 'epoch': 0.61}\n",
      "{'loss': 0.3051, 'grad_norm': 4.809910774230957, 'learning_rate': 2.3760000000000003e-05, 'epoch': 0.62}\n",
      "{'loss': 0.2464, 'grad_norm': 4.123154163360596, 'learning_rate': 2.3599999999999998e-05, 'epoch': 0.64}\n",
      "{'loss': 0.2653, 'grad_norm': 5.340731143951416, 'learning_rate': 2.344e-05, 'epoch': 0.66}\n",
      "{'loss': 0.2558, 'grad_norm': 4.047858715057373, 'learning_rate': 2.328e-05, 'epoch': 0.67}\n",
      "{'loss': 0.3005, 'grad_norm': 2.5724010467529297, 'learning_rate': 2.3120000000000002e-05, 'epoch': 0.69}\n",
      "{'loss': 0.2517, 'grad_norm': 4.660347938537598, 'learning_rate': 2.296e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2959, 'grad_norm': 2.765425443649292, 'learning_rate': 2.2800000000000002e-05, 'epoch': 0.72}\n",
      "{'loss': 0.2921, 'grad_norm': 1.7731164693832397, 'learning_rate': 2.2640000000000003e-05, 'epoch': 0.74}\n",
      "{'loss': 0.2674, 'grad_norm': 2.1901936531066895, 'learning_rate': 2.2479999999999998e-05, 'epoch': 0.75}\n",
      "{'loss': 0.2557, 'grad_norm': 3.83071231842041, 'learning_rate': 2.232e-05, 'epoch': 0.77}\n",
      "{'loss': 0.2171, 'grad_norm': 1.6692190170288086, 'learning_rate': 2.216e-05, 'epoch': 0.78}\n",
      "{'loss': 0.2509, 'grad_norm': 4.89913272857666, 'learning_rate': 2.2e-05, 'epoch': 0.8}\n",
      "{'loss': 0.2736, 'grad_norm': 4.476259231567383, 'learning_rate': 2.184e-05, 'epoch': 0.82}\n",
      "{'loss': 0.2792, 'grad_norm': 3.381396532058716, 'learning_rate': 2.1680000000000002e-05, 'epoch': 0.83}\n",
      "{'loss': 0.2522, 'grad_norm': 2.0525052547454834, 'learning_rate': 2.152e-05, 'epoch': 0.85}\n",
      "{'loss': 0.2659, 'grad_norm': 3.06626558303833, 'learning_rate': 2.136e-05, 'epoch': 0.86}\n",
      "{'loss': 0.2503, 'grad_norm': 3.2305009365081787, 'learning_rate': 2.12e-05, 'epoch': 0.88}\n",
      "{'loss': 0.2841, 'grad_norm': 3.2410953044891357, 'learning_rate': 2.1040000000000002e-05, 'epoch': 0.9}\n",
      "{'loss': 0.2983, 'grad_norm': 2.295720338821411, 'learning_rate': 2.088e-05, 'epoch': 0.91}\n",
      "{'loss': 0.2264, 'grad_norm': 1.8568389415740967, 'learning_rate': 2.072e-05, 'epoch': 0.93}\n",
      "{'loss': 0.2759, 'grad_norm': 5.805394649505615, 'learning_rate': 2.056e-05, 'epoch': 0.94}\n",
      "{'loss': 0.2594, 'grad_norm': 6.097381114959717, 'learning_rate': 2.04e-05, 'epoch': 0.96}\n",
      "{'loss': 0.2856, 'grad_norm': 3.3565280437469482, 'learning_rate': 2.024e-05, 'epoch': 0.98}\n",
      "{'loss': 0.2446, 'grad_norm': 1.996513843536377, 'learning_rate': 2.008e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c83087e49154851b7a24bf916ad3fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23756061494350433, 'eval_f1': 0.9057680968468685, 'eval_runtime': 56.4564, 'eval_samples_per_second': 177.128, 'eval_steps_per_second': 2.781, 'epoch': 1.0}\n",
      "{'loss': 0.2758, 'grad_norm': 3.2346560955047607, 'learning_rate': 1.9920000000000002e-05, 'epoch': 1.01}\n",
      "{'loss': 0.237, 'grad_norm': 6.097232818603516, 'learning_rate': 1.976e-05, 'epoch': 1.02}\n",
      "{'loss': 0.2652, 'grad_norm': 5.409407615661621, 'learning_rate': 1.96e-05, 'epoch': 1.04}\n",
      "{'loss': 0.2417, 'grad_norm': 2.236219882965088, 'learning_rate': 1.944e-05, 'epoch': 1.06}\n",
      "{'loss': 0.2025, 'grad_norm': 3.221360683441162, 'learning_rate': 1.9280000000000002e-05, 'epoch': 1.07}\n",
      "{'loss': 0.2284, 'grad_norm': 2.56514573097229, 'learning_rate': 1.912e-05, 'epoch': 1.09}\n",
      "{'loss': 0.2308, 'grad_norm': 5.76525354385376, 'learning_rate': 1.896e-05, 'epoch': 1.1}\n",
      "{'loss': 0.247, 'grad_norm': 7.27003812789917, 'learning_rate': 1.8800000000000003e-05, 'epoch': 1.12}\n",
      "{'loss': 0.2791, 'grad_norm': 3.645059823989868, 'learning_rate': 1.8639999999999998e-05, 'epoch': 1.14}\n",
      "{'loss': 0.2507, 'grad_norm': 1.9082683324813843, 'learning_rate': 1.848e-05, 'epoch': 1.15}\n",
      "{'loss': 0.2229, 'grad_norm': 2.1794779300689697, 'learning_rate': 1.832e-05, 'epoch': 1.17}\n",
      "{'loss': 0.2388, 'grad_norm': 2.9742720127105713, 'learning_rate': 1.816e-05, 'epoch': 1.18}\n",
      "{'loss': 0.2273, 'grad_norm': 4.2599334716796875, 'learning_rate': 1.8e-05, 'epoch': 1.2}\n",
      "{'loss': 0.2676, 'grad_norm': 2.6393935680389404, 'learning_rate': 1.7840000000000002e-05, 'epoch': 1.22}\n",
      "{'loss': 0.2496, 'grad_norm': 2.17868709564209, 'learning_rate': 1.768e-05, 'epoch': 1.23}\n",
      "{'loss': 0.2179, 'grad_norm': 2.3827476501464844, 'learning_rate': 1.7519999999999998e-05, 'epoch': 1.25}\n",
      "{'loss': 0.2314, 'grad_norm': 3.9635086059570312, 'learning_rate': 1.736e-05, 'epoch': 1.26}\n",
      "{'loss': 0.284, 'grad_norm': 4.939438819885254, 'learning_rate': 1.72e-05, 'epoch': 1.28}\n",
      "{'loss': 0.2291, 'grad_norm': 2.6205663681030273, 'learning_rate': 1.704e-05, 'epoch': 1.3}\n",
      "{'loss': 0.2534, 'grad_norm': 4.102180480957031, 'learning_rate': 1.688e-05, 'epoch': 1.31}\n",
      "{'loss': 0.2174, 'grad_norm': 2.403292179107666, 'learning_rate': 1.672e-05, 'epoch': 1.33}\n",
      "{'loss': 0.2459, 'grad_norm': 2.642677068710327, 'learning_rate': 1.656e-05, 'epoch': 1.34}\n",
      "{'loss': 0.2203, 'grad_norm': 5.734772205352783, 'learning_rate': 1.64e-05, 'epoch': 1.36}\n",
      "{'loss': 0.2132, 'grad_norm': 1.6435803174972534, 'learning_rate': 1.624e-05, 'epoch': 1.38}\n",
      "{'loss': 0.2234, 'grad_norm': 4.214375972747803, 'learning_rate': 1.6080000000000002e-05, 'epoch': 1.39}\n",
      "{'loss': 0.2229, 'grad_norm': 2.1144602298736572, 'learning_rate': 1.592e-05, 'epoch': 1.41}\n",
      "{'loss': 0.1942, 'grad_norm': 4.9577836990356445, 'learning_rate': 1.576e-05, 'epoch': 1.42}\n",
      "{'loss': 0.2244, 'grad_norm': 4.639377593994141, 'learning_rate': 1.56e-05, 'epoch': 1.44}\n",
      "{'loss': 0.236, 'grad_norm': 3.039930582046509, 'learning_rate': 1.544e-05, 'epoch': 1.46}\n",
      "{'loss': 0.2362, 'grad_norm': 3.528884172439575, 'learning_rate': 1.528e-05, 'epoch': 1.47}\n",
      "{'loss': 0.2428, 'grad_norm': 2.1722028255462646, 'learning_rate': 1.5120000000000001e-05, 'epoch': 1.49}\n",
      "{'loss': 0.2284, 'grad_norm': 2.167243719100952, 'learning_rate': 1.4959999999999999e-05, 'epoch': 1.5}\n",
      "{'loss': 0.2326, 'grad_norm': 4.709047794342041, 'learning_rate': 1.48e-05, 'epoch': 1.52}\n",
      "{'loss': 0.2438, 'grad_norm': 6.559138774871826, 'learning_rate': 1.464e-05, 'epoch': 1.54}\n",
      "{'loss': 0.2294, 'grad_norm': 2.2571821212768555, 'learning_rate': 1.448e-05, 'epoch': 1.55}\n",
      "{'loss': 0.2418, 'grad_norm': 5.273871898651123, 'learning_rate': 1.432e-05, 'epoch': 1.57}\n",
      "{'loss': 0.2215, 'grad_norm': 2.576601028442383, 'learning_rate': 1.416e-05, 'epoch': 1.58}\n",
      "{'loss': 0.226, 'grad_norm': 5.644504547119141, 'learning_rate': 1.4e-05, 'epoch': 1.6}\n",
      "{'loss': 0.2118, 'grad_norm': 2.329300880432129, 'learning_rate': 1.384e-05, 'epoch': 1.62}\n",
      "{'loss': 0.2574, 'grad_norm': 4.299596309661865, 'learning_rate': 1.3680000000000001e-05, 'epoch': 1.63}\n",
      "{'loss': 0.2112, 'grad_norm': 3.983961820602417, 'learning_rate': 1.352e-05, 'epoch': 1.65}\n",
      "{'loss': 0.22, 'grad_norm': 1.9868426322937012, 'learning_rate': 1.336e-05, 'epoch': 1.66}\n",
      "{'loss': 0.2463, 'grad_norm': 7.095836639404297, 'learning_rate': 1.32e-05, 'epoch': 1.68}\n",
      "{'loss': 0.1931, 'grad_norm': 2.9053072929382324, 'learning_rate': 1.304e-05, 'epoch': 1.7}\n",
      "{'loss': 0.2293, 'grad_norm': 5.469119548797607, 'learning_rate': 1.288e-05, 'epoch': 1.71}\n",
      "{'loss': 0.2418, 'grad_norm': 2.5235519409179688, 'learning_rate': 1.272e-05, 'epoch': 1.73}\n",
      "{'loss': 0.2194, 'grad_norm': 2.2994983196258545, 'learning_rate': 1.2560000000000002e-05, 'epoch': 1.74}\n",
      "{'loss': 0.2309, 'grad_norm': 4.023059368133545, 'learning_rate': 1.24e-05, 'epoch': 1.76}\n",
      "{'loss': 0.2236, 'grad_norm': 2.7141342163085938, 'learning_rate': 1.224e-05, 'epoch': 1.78}\n",
      "{'loss': 0.2304, 'grad_norm': 2.50478196144104, 'learning_rate': 1.2080000000000001e-05, 'epoch': 1.79}\n",
      "{'loss': 0.2368, 'grad_norm': 2.45892333984375, 'learning_rate': 1.192e-05, 'epoch': 1.81}\n",
      "{'loss': 0.2484, 'grad_norm': 4.374326229095459, 'learning_rate': 1.1760000000000001e-05, 'epoch': 1.82}\n",
      "{'loss': 0.2266, 'grad_norm': 3.79522967338562, 'learning_rate': 1.16e-05, 'epoch': 1.84}\n",
      "{'loss': 0.2139, 'grad_norm': 3.690917730331421, 'learning_rate': 1.144e-05, 'epoch': 1.86}\n",
      "{'loss': 0.2414, 'grad_norm': 3.452000379562378, 'learning_rate': 1.128e-05, 'epoch': 1.87}\n",
      "{'loss': 0.2025, 'grad_norm': 3.112839460372925, 'learning_rate': 1.112e-05, 'epoch': 1.89}\n",
      "{'loss': 0.2112, 'grad_norm': 2.1381146907806396, 'learning_rate': 1.096e-05, 'epoch': 1.9}\n",
      "{'loss': 0.2707, 'grad_norm': 2.548013687133789, 'learning_rate': 1.08e-05, 'epoch': 1.92}\n",
      "{'loss': 0.2054, 'grad_norm': 3.357998847961426, 'learning_rate': 1.0640000000000001e-05, 'epoch': 1.94}\n",
      "{'loss': 0.2233, 'grad_norm': 2.1784915924072266, 'learning_rate': 1.048e-05, 'epoch': 1.95}\n",
      "{'loss': 0.2256, 'grad_norm': 1.7826101779937744, 'learning_rate': 1.032e-05, 'epoch': 1.97}\n",
      "{'loss': 0.2001, 'grad_norm': 3.4238462448120117, 'learning_rate': 1.0160000000000001e-05, 'epoch': 1.98}\n",
      "{'loss': 0.2145, 'grad_norm': 3.6290106773376465, 'learning_rate': 9.999999999999999e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8614ce1adb5a4628acfdaff40002f4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22694045305252075, 'eval_f1': 0.9149914991499151, 'eval_runtime': 56.4748, 'eval_samples_per_second': 177.07, 'eval_steps_per_second': 2.78, 'epoch': 2.0}\n",
      "{'loss': 0.2377, 'grad_norm': 4.046150207519531, 'learning_rate': 9.84e-06, 'epoch': 2.02}\n",
      "{'loss': 0.2081, 'grad_norm': 2.6765658855438232, 'learning_rate': 9.68e-06, 'epoch': 2.03}\n",
      "{'loss': 0.177, 'grad_norm': 3.790120840072632, 'learning_rate': 9.52e-06, 'epoch': 2.05}\n",
      "{'loss': 0.1886, 'grad_norm': 2.427640676498413, 'learning_rate': 9.36e-06, 'epoch': 2.06}\n",
      "{'loss': 0.2241, 'grad_norm': 2.901737928390503, 'learning_rate': 9.2e-06, 'epoch': 2.08}\n",
      "{'loss': 0.2713, 'grad_norm': 3.3363330364227295, 'learning_rate': 9.04e-06, 'epoch': 2.1}\n",
      "{'loss': 0.2497, 'grad_norm': 4.722509384155273, 'learning_rate': 8.88e-06, 'epoch': 2.11}\n",
      "{'loss': 0.1962, 'grad_norm': 3.5236868858337402, 'learning_rate': 8.720000000000001e-06, 'epoch': 2.13}\n",
      "{'loss': 0.2056, 'grad_norm': 4.68654203414917, 'learning_rate': 8.56e-06, 'epoch': 2.14}\n",
      "{'loss': 0.1869, 'grad_norm': 2.572265148162842, 'learning_rate': 8.400000000000001e-06, 'epoch': 2.16}\n",
      "{'loss': 0.2017, 'grad_norm': 3.16318678855896, 'learning_rate': 8.24e-06, 'epoch': 2.18}\n",
      "{'loss': 0.1788, 'grad_norm': 2.7943406105041504, 'learning_rate': 8.079999999999999e-06, 'epoch': 2.19}\n",
      "{'loss': 0.1886, 'grad_norm': 3.792675495147705, 'learning_rate': 7.92e-06, 'epoch': 2.21}\n",
      "{'loss': 0.2343, 'grad_norm': 2.632570505142212, 'learning_rate': 7.76e-06, 'epoch': 2.22}\n",
      "{'loss': 0.1969, 'grad_norm': 4.1286301612854, 'learning_rate': 7.600000000000001e-06, 'epoch': 2.24}\n",
      "{'loss': 0.1954, 'grad_norm': 2.9071364402770996, 'learning_rate': 7.44e-06, 'epoch': 2.26}\n",
      "{'loss': 0.2376, 'grad_norm': 5.7861809730529785, 'learning_rate': 7.280000000000001e-06, 'epoch': 2.27}\n",
      "{'loss': 0.2247, 'grad_norm': 1.9009188413619995, 'learning_rate': 7.1200000000000004e-06, 'epoch': 2.29}\n",
      "{'loss': 0.2184, 'grad_norm': 3.9789206981658936, 'learning_rate': 6.96e-06, 'epoch': 2.3}\n",
      "{'loss': 0.2081, 'grad_norm': 4.526177883148193, 'learning_rate': 6.8e-06, 'epoch': 2.32}\n",
      "{'loss': 0.1694, 'grad_norm': 2.236776828765869, 'learning_rate': 6.64e-06, 'epoch': 2.34}\n",
      "{'loss': 0.2198, 'grad_norm': 2.6256401538848877, 'learning_rate': 6.48e-06, 'epoch': 2.35}\n",
      "{'loss': 0.2286, 'grad_norm': 2.1500864028930664, 'learning_rate': 6.3200000000000005e-06, 'epoch': 2.37}\n",
      "{'loss': 0.1906, 'grad_norm': 4.096667766571045, 'learning_rate': 6.16e-06, 'epoch': 2.38}\n",
      "{'loss': 0.1915, 'grad_norm': 2.457458257675171, 'learning_rate': 6e-06, 'epoch': 2.4}\n",
      "{'loss': 0.1899, 'grad_norm': 2.435091733932495, 'learning_rate': 5.84e-06, 'epoch': 2.42}\n",
      "{'loss': 0.2111, 'grad_norm': 6.29506778717041, 'learning_rate': 5.68e-06, 'epoch': 2.43}\n",
      "{'loss': 0.2237, 'grad_norm': 2.8336293697357178, 'learning_rate': 5.52e-06, 'epoch': 2.45}\n",
      "{'loss': 0.1889, 'grad_norm': 2.0384104251861572, 'learning_rate': 5.36e-06, 'epoch': 2.46}\n",
      "{'loss': 0.2524, 'grad_norm': 3.9058079719543457, 'learning_rate': 5.2e-06, 'epoch': 2.48}\n",
      "{'loss': 0.2292, 'grad_norm': 3.526577949523926, 'learning_rate': 5.04e-06, 'epoch': 2.5}\n",
      "{'loss': 0.1739, 'grad_norm': 4.667079925537109, 'learning_rate': 4.88e-06, 'epoch': 2.51}\n",
      "{'loss': 0.2083, 'grad_norm': 2.745223045349121, 'learning_rate': 4.72e-06, 'epoch': 2.53}\n",
      "{'loss': 0.1891, 'grad_norm': 2.292278528213501, 'learning_rate': 4.56e-06, 'epoch': 2.54}\n",
      "{'loss': 0.1932, 'grad_norm': 3.526401996612549, 'learning_rate': 4.4e-06, 'epoch': 2.56}\n",
      "{'loss': 0.2111, 'grad_norm': 2.863640546798706, 'learning_rate': 4.24e-06, 'epoch': 2.58}\n",
      "{'loss': 0.2139, 'grad_norm': 3.5397939682006836, 'learning_rate': 4.080000000000001e-06, 'epoch': 2.59}\n",
      "{'loss': 0.1836, 'grad_norm': 3.413947582244873, 'learning_rate': 3.92e-06, 'epoch': 2.61}\n",
      "{'loss': 0.2068, 'grad_norm': 3.0255606174468994, 'learning_rate': 3.76e-06, 'epoch': 2.62}\n",
      "{'loss': 0.1848, 'grad_norm': 2.4112160205841064, 'learning_rate': 3.6e-06, 'epoch': 2.64}\n",
      "{'loss': 0.1834, 'grad_norm': 2.309053659439087, 'learning_rate': 3.44e-06, 'epoch': 2.66}\n",
      "{'loss': 0.1753, 'grad_norm': 4.606227874755859, 'learning_rate': 3.2800000000000004e-06, 'epoch': 2.67}\n",
      "{'loss': 0.2156, 'grad_norm': 4.617539405822754, 'learning_rate': 3.1199999999999998e-06, 'epoch': 2.69}\n",
      "{'loss': 0.2254, 'grad_norm': 1.8536685705184937, 'learning_rate': 2.96e-06, 'epoch': 2.7}\n",
      "{'loss': 0.1843, 'grad_norm': 2.6015632152557373, 'learning_rate': 2.8000000000000003e-06, 'epoch': 2.72}\n",
      "{'loss': 0.2396, 'grad_norm': 3.2559423446655273, 'learning_rate': 2.6399999999999997e-06, 'epoch': 2.74}\n",
      "{'loss': 0.1639, 'grad_norm': 2.471503257751465, 'learning_rate': 2.48e-06, 'epoch': 2.75}\n",
      "{'loss': 0.1927, 'grad_norm': 4.084872722625732, 'learning_rate': 2.3200000000000002e-06, 'epoch': 2.77}\n",
      "{'loss': 0.1929, 'grad_norm': 3.4021990299224854, 'learning_rate': 2.16e-06, 'epoch': 2.78}\n",
      "{'loss': 0.1909, 'grad_norm': 4.609898567199707, 'learning_rate': 2e-06, 'epoch': 2.8}\n",
      "{'loss': 0.2053, 'grad_norm': 5.924870491027832, 'learning_rate': 1.84e-06, 'epoch': 2.82}\n",
      "{'loss': 0.1966, 'grad_norm': 3.750312566757202, 'learning_rate': 1.68e-06, 'epoch': 2.83}\n",
      "{'loss': 0.2401, 'grad_norm': 2.909433126449585, 'learning_rate': 1.52e-06, 'epoch': 2.85}\n",
      "{'loss': 0.1957, 'grad_norm': 4.823887348175049, 'learning_rate': 1.3600000000000001e-06, 'epoch': 2.86}\n",
      "{'loss': 0.1932, 'grad_norm': 2.6962270736694336, 'learning_rate': 1.2000000000000002e-06, 'epoch': 2.88}\n",
      "{'loss': 0.1951, 'grad_norm': 3.152139902114868, 'learning_rate': 1.04e-06, 'epoch': 2.9}\n",
      "{'loss': 0.1981, 'grad_norm': 3.2526512145996094, 'learning_rate': 8.8e-07, 'epoch': 2.91}\n",
      "{'loss': 0.2001, 'grad_norm': 4.742244243621826, 'learning_rate': 7.2e-07, 'epoch': 2.93}\n",
      "{'loss': 0.1783, 'grad_norm': 2.979583263397217, 'learning_rate': 5.6e-07, 'epoch': 2.94}\n",
      "{'loss': 0.1895, 'grad_norm': 6.059163570404053, 'learning_rate': 4.0000000000000003e-07, 'epoch': 2.96}\n",
      "{'loss': 0.2161, 'grad_norm': 4.620605945587158, 'learning_rate': 2.4000000000000003e-07, 'epoch': 2.98}\n",
      "{'loss': 0.1719, 'grad_norm': 2.4941940307617188, 'learning_rate': 8e-08, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4e911179d64b35aed4fb05ca53849d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22296598553657532, 'eval_f1': 0.9182987573240989, 'eval_runtime': 56.5586, 'eval_samples_per_second': 176.808, 'eval_steps_per_second': 2.776, 'epoch': 3.0}\n",
      "{'train_runtime': 2397.8584, 'train_samples_per_second': 50.045, 'train_steps_per_second': 0.782, 'train_loss': 0.25412537110646566, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1875, training_loss=0.25412537110646566, metrics={'train_runtime': 2397.8584, 'train_samples_per_second': 50.045, 'train_steps_per_second': 0.782, 'total_flos': 1245553977600000.0, 'train_loss': 0.25412537110646566, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 0 if torch.cuda.is_available() else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipe = transformers.pipeline(\n",
    "    task='text-classification',\n",
    "    model=classification_model,\n",
    "    tokenizer=tokenizer_model,\n",
    "    batch_size=4,\n",
    "    device=device_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AltTextDataset:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        encoded_data = tokenizer_model(\n",
    "            row[\"text\"],\n",
    "            max_length=10,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(encoded_data[\"input_ids\"]),\n",
    "            \"attention_mask\": torch.tensor(encoded_data[\"attention_mask\"]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB = pd.read_csv(\"/Users/fariddamania/Downloads/SEM VII/SNLP/Dataset/IMDB Dataset.csv\").rename(columns={\"review\": \"text\"})\n",
    "IMDB[\"label\"] = IMDB[\"sentiment\"].map(label_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/Users/fariddamania/Downloads/SEM VII/SNLP/Finetuning Transformers/my_model_output/checkpoint-1875\"\n",
    "tokenizer_model = transformers.AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "classification_model = transformers.AutoModelForSequenceClassification.from_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_instance = AltTextDataset(IMDB)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_instance,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.11/site-packages (0.19.1)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.11/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5989, 0.3815, 0.6990],\n",
      "        [0.5309, 0.1359, 0.7691],\n",
      "        [0.1670, 0.5767, 0.9900],\n",
      "        [0.9364, 0.3018, 0.9668],\n",
      "        [0.8974, 0.0624, 0.4086]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.11/site-packages (0.19.1)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.11/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Use the M1 GPU\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m classification_model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"mps\")  # Use the M1 GPU\n",
    "classification_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_context = \"My name is Farid Damania. I was born in Daman.\"\n",
    "sample_question = \"Where was Farid born?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_context = \"My name is Farid Damania. I was born in Daman.\"\n",
    "sample_question = \"Where was Farid born?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classification_model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_model' is not defined"
     ]
    }
   ],
   "source": [
    "classification_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'AltTextDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, data_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data_batch)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Move data to CUDA\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:440\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1038\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1031\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1038\u001b[0m w\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Popen(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_context\u001b[38;5;241m.\u001b[39mget_context()\u001b[38;5;241m.\u001b[39mProcess\u001b[38;5;241m.\u001b[39m_Popen(process_obj)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(process_obj)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_launch(process_obj)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(fp\u001b[38;5;241m.\u001b[39mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index, data_batch in enumerate(data_loader):\n",
    "    print(data_batch)\n",
    "    \n",
    "    # Move data to CUDA\n",
    "    data_batch = {key: value.to('cuda') for key, value in data_batch.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = classification_model(input_ids=data_batch[\"input_ids\"], attention_mask=data_batch[\"attention_mask\"])\n",
    "    \n",
    "    if index == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipe = transformers.pipeline(\n",
    "    \"text-classification\",\n",
    "    model=checkpoint_path,\n",
    "    batch_size=4,\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipe([\"I hated how bad the movie was.\"] * 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
